{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from dask.distributed import Client\n",
    "from seapopym.configuration.no_transport.parameter import ForcingParameters\n",
    "\n",
    "# from seapopym.configuration.parameters.parameter_environment import (\n",
    "#     ChunkParameter,\n",
    "#     ClientParameter,\n",
    "#     EnvironmentParameter,\n",
    "# )\n",
    "from seapopym.configuration.parameters.parameter_forcing import ForcingUnit\n",
    "from seapopym.standard.units import StandardUnitsLabels\n",
    "\n",
    "from seapopym_optimization import Observation, constraint\n",
    "from seapopym_optimization.cost_function import NoTransportCostFunction\n",
    "from seapopym_optimization.functional_groups import FunctionalGroupOptimizeNoTransport, Parameter\n",
    "from seapopym_optimization.genetic_algorithm import GeneticAlgorithm, GeneticAlgorithmParameters\n",
    "from seapopym_optimization.taylor_diagram import ModTaylorDiagram, generate_mod_taylor_diagram\n",
    "\n",
    "xr.set_options(\n",
    "    display_expand_attrs=False,\n",
    "    display_expand_data_vars=False,\n",
    "    display_expand_coords=False,\n",
    "    display_expand_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_forcing = \"../../../1_data_processing/1_1_Forcing/data/1_products/all_stations_cmems_climato.zarr\"\n",
    "path_to_observed_npp_hot = \"../../../1_data_processing/1_1_Forcing/data/1_products/Hot_observed_npp_climato.zarr\"\n",
    "path_to_obs = {\n",
    "    \"BATS\": \"../../../1_data_processing/1_1_Forcing/data/1_products/Bats_obs_zoo_climato_monthly_2002_2015.zarr\",\n",
    "    \"HOT\": \"../../../1_data_processing/1_1_Forcing/data/1_products/Hot_obs_zoo_climato_monthly_2002_2015.zarr\",\n",
    "    \"PAPA\": \"../../../1_data_processing/1_1_Forcing/data/1_products/Papa_obs_zoo_climato_monthly_2002_2015.zarr\",\n",
    "    \"CALCOFI\": \"../../../1_data_processing/1_1_Forcing/data/1_products/Calcofi_obs_zoo_climato_monthly_2002_2015.zarr\",\n",
    "}\n",
    "export_file_name = \"Climato_all_4_stations_2_groups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_START = \"2005-01-01\"\n",
    "TIME_END = \"2007-01-01\"\n",
    "STABILIZATION_TIME = 5\n",
    "SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client(n_workers=2, threads_per_worker=1, memory_limit=\"16GB\")\n",
    "client = Client(n_workers=2, threads_per_worker=2, memory_limit=\"20GB\")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forcing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing = xr.open_zarr(path_to_forcing)\n",
    "forcing = forcing.sel(time=slice(TIME_START, TIME_END))\n",
    "forcing[\"T\"].attrs[\"units\"] = StandardUnitsLabels.temperature.units\n",
    "forcing.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load observed npp in HOT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_npp = xr.open_zarr(path_to_observed_npp_hot)\n",
    "observed_npp = observed_npp.sel(time=slice(TIME_START, TIME_END))\n",
    "observed_npp.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert weekly npp observations to forcing calendar and use interpolation to fill in the gaps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgpm_hot = forcing.npp.sel(latitude=observed_npp.latitude, longitude=observed_npp.longitude)  # .data\n",
    "observed_npp = observed_npp.interp_calendar(vgpm_hot.time).interpolate_na(\n",
    "    dim=\"time\", method=\"linear\", fill_value=\"extrapolate\"\n",
    ")\n",
    "observed_npp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace hot primary production in forcing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing.npp.sel(latitude=observed_npp.latitude, longitude=observed_npp.longitude).data = observed_npp[\"l12\"].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epipelagic layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_layer_depth = forcing[\"pelagic_layer_depth\"].sel(depth=0)\n",
    "epi_layer_depth = epi_layer_depth.resample(time=\"1D\").mean()\n",
    "epi_layer_depth.attrs[\"units\"] = \"meter\"\n",
    "epi_layer_depth = epi_layer_depth.pint.quantify()\n",
    "epi_layer_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Observed NPP -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.set_options(keep_attrs=True):\n",
    "    observations = {}\n",
    "    for name_obs, path_obs in path_to_obs.items():\n",
    "        obs = xr.open_zarr(path_obs).load()\n",
    "        # Remove the X first months to let the model reach the stationary state.\n",
    "        obs = obs.sel(time=slice(TIME_START, TIME_END)).isel(time=slice(STABILIZATION_TIME, None))\n",
    "        obs = obs.dropna(\"time\", how=\"all\")\n",
    "        obs = obs.pint.quantify()\n",
    "        obs = obs * epi_layer_depth\n",
    "        observations[name_obs] = obs[[\"day\", \"night\"]].drop_vars(\"depth\").pint.dequantify()\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send forcing to each core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forcing[\"T\"].chunk()\n",
    "# forcing[\"npp\"].chunk()\n",
    "# observations = [\n",
    "#     Observation(name=name, observation=obs.chunk(), observation_type=\"monthly\") for name, obs in observations.items()\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing[\"T\"] = forcing[\"T\"].astype(np.float32)\n",
    "forcing[\"npp\"] = forcing[\"npp\"].astype(np.float32)\n",
    "\n",
    "# forcing = forcing.chunk()\n",
    "# observations = {name: obs.chunk() for name, obs in observations.items()}\n",
    "\n",
    "observations = [\n",
    "    Observation(name=name, observation=obs.astype(np.float32).load(), observation_type=\"monthly\")\n",
    "    for name, obs in observations.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create structure for SeapoPym simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_parameters = ForcingParameters(\n",
    "    temperature=ForcingUnit(forcing=forcing[\"T\"], resolution=1 / 12, timestep=1),\n",
    "    primary_production=ForcingUnit(forcing=forcing[\"npp\"], resolution=1 / 12, timestep=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the parameters and the cost function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functional_groups = [\n",
    "    FunctionalGroupOptimizeNoTransport(\n",
    "        name=\"D1N1\",\n",
    "        day_layer=0,\n",
    "        night_layer=0,\n",
    "        energy_coefficient=Parameter(\"D1N1_energy_coefficient\", 0.001, 0.4),\n",
    "        tr_rate=Parameter(\"D1N1_tr_rate\", -0.3, -0.001),\n",
    "        tr_max=Parameter(\"D1N1_tr_max\", 0, 50),\n",
    "        inv_lambda_rate=Parameter(\"D1N1_inv_lambda_rate\", -0.3, -0.001),\n",
    "        inv_lambda_max=Parameter(\"D1N1_inv_lambda_max\", 100, 200),\n",
    "    ),\n",
    "    FunctionalGroupOptimizeNoTransport(\n",
    "        name=\"D2N1\",\n",
    "        day_layer=1,\n",
    "        night_layer=0,\n",
    "        energy_coefficient=Parameter(\"D2N1_energy_coefficient\", 0.001, 0.4),\n",
    "        tr_rate=Parameter(\"D2N1_tr_rate\", -0.3, -0.001),\n",
    "        tr_max=Parameter(\"D2N1_tr_max\", 0, 50),\n",
    "        inv_lambda_rate=Parameter(\"D2N1_inv_lambda_rate\", -0.3, -0.001),\n",
    "        inv_lambda_max=Parameter(\"D2N1_inv_lambda_max\", 100, 200),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from seapopym.configuration.parameters.parameter_environment import EnvironmentParameter, ChunkParameter\n",
    "\n",
    "cost_function = NoTransportCostFunction(\n",
    "    functional_groups=functional_groups,\n",
    "    forcing_parameters=forcing_parameters,\n",
    "    observations=observations,\n",
    "    normalized_mse=True,\n",
    "    root_mse=True,\n",
    "    # environment_parameters=EnvironmentParameter(chunk=ChunkParameter(functional_group=2)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional : Compute max memory size + execution time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import time\n",
    "\n",
    "# from seapopym_optimization.wrapper import FunctionalGroupGeneratorNoTransport, model_generator_no_transport\n",
    "\n",
    "# model = model_generator_no_transport(\n",
    "#     forcing_parameters=forcing_parameters,\n",
    "#     fg_parameters=FunctionalGroupGeneratorNoTransport(\n",
    "#         [\n",
    "#             [0, 0, 0.1, 50, -0.1, 150, -0.1],\n",
    "#             [0, 1, 0.1, 50, -0.1, 150, -0.1],\n",
    "#         ],\n",
    "#         groups_name=[\"D1N1\", \"D2N1\"],\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "\n",
    "# time_start = time()\n",
    "# model.run()\n",
    "# time_end = time()\n",
    "\n",
    "# print(model.expected_memory_usage)\n",
    "# print(f\"Time to run the model: {time_end - time_start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the genetic algorithm meta parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_algo_parameters = GeneticAlgorithmParameters(\n",
    "    MUTPB=0.30,\n",
    "    INDPB=0.2,\n",
    "    ETA=5,\n",
    "    CXPB=0.7,\n",
    "    NGEN=1,\n",
    "    POP_SIZE=4000,\n",
    "    cost_function_weight=(-1, -1, -1, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a constraint to limit the total of energy transfert coefficient to 100%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_energy = constraint.ConstraintNoTransportEnergyCoefficient(\n",
    "    parameters_name=[\"D1N1_energy_coefficient\", \"D2N1_energy_coefficient\"],\n",
    "    min_energy_coef_value=0,\n",
    "    max_energy_coef_value=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly, create the Genetic Algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_algo = GeneticAlgorithm(\n",
    "    cost_function=cost_function,\n",
    "    parameter_genetic_algorithm=genetic_algo_parameters,\n",
    "    constraint=[constraint_energy],\n",
    "    client=client,\n",
    "    logbook_path=f\"{export_file_name}_logbook.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And watch the magic on the Dask dashboard :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_algo.client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = genetic_algo.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.hall_of_fame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.fitness_evolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.parameters_standardized_deviation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.parameters_scatter_matrix(nbest=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = viewer.box_plot(5, nbest=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\n",
    "    [\"D1N1_energy_coefficient\", \"D1N1_tr_rate\", \"D1N1_tr_max\", \"D1N1_inv_lambda_rate\", \"D1N1_inv_lambda_max\"],\n",
    "    [\"D2N1_energy_coefficient\", \"D2N1_tr_rate\", \"D2N1_tr_max\", \"D2N1_inv_lambda_rate\", \"D2N1_inv_lambda_max\"],\n",
    "]\n",
    "\n",
    "fig = viewer.parallel_coordinates(nbest=2_000, unselected_opacity=0, parameter_groups=groups, uniformed=True)\n",
    "\n",
    "for group in fig:\n",
    "    display(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    for i, trace in enumerate(fig):\n",
    "        trace.write_html(f\"Parallel_coordinates_{export_file_name}_{i}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series of X best individuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_figures = viewer.time_series(10, title=list(path_to_obs.keys()), client=client)\n",
    "for figure in all_figures:\n",
    "    figure.update_layout(width=1000, height=600)\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    fig.write_html(f\"Biomass_best_individuals_{export_file_name}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix of X best individuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = viewer.parameters_correlation_matrix(10_000)\n",
    "fig.update_layout(width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    fig.write_html(f\"Correlation_best_individuals_{export_file_name}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def weighted_correlation_matrix(X, w):\n",
    "    \"\"\"\n",
    "    Calcule la matrice de corrélation pondérée de Pearson pour un ensemble de variables.\n",
    "\n",
    "    Paramètres :\n",
    "    X : array-like (NxM) - Matrice des observations (N observations, M variables)\n",
    "    w : array-like (N,)  - Poids associés à chaque observation\n",
    "\n",
    "    Retourne :\n",
    "    R_w : array (MxM) - Matrice de corrélation pondérée (M variables x M variables)\n",
    "    \"\"\"\n",
    "    X = np.array(X)\n",
    "    w = np.array(w).reshape(-1, 1)  # Convertir en colonne (N,1) si nécessaire\n",
    "\n",
    "    # Nombre de variables\n",
    "    M = X.shape[1]\n",
    "\n",
    "    # Moyennes pondérées pour chaque variable\n",
    "    mean_w = np.sum(w * X, axis=0) / np.sum(w)\n",
    "\n",
    "    # Écarts-types pondérés pour chaque variable\n",
    "    std_w = np.sqrt(np.sum(w * (X - mean_w) ** 2, axis=0))\n",
    "\n",
    "    # Matrice de covariance pondérée\n",
    "    cov_w = np.dot((X - mean_w).T, w * (X - mean_w))\n",
    "\n",
    "    # Matrice de corrélation pondérée\n",
    "    R_w = cov_w / np.outer(std_w, std_w)\n",
    "\n",
    "    # Nan sur la diagonale\n",
    "    np.fill_diagonal(R_w, np.nan)\n",
    "\n",
    "    return R_w\n",
    "\n",
    "\n",
    "X = viewer.hall_of_fame.to_numpy()[:, :-1]\n",
    "# Solution polynomiale\n",
    "# w = np.abs(1 / viewer.hall_of_fame[\"fitness\"].to_numpy())\n",
    "# Solution linéaire\n",
    "w = viewer.hall_of_fame[\"fitness\"].to_numpy()\n",
    "w = (-w) + np.max(w)\n",
    "\n",
    "R_w = weighted_correlation_matrix(X, w)\n",
    "\n",
    "fig = px.imshow(\n",
    "    R_w,\n",
    "    width=800,\n",
    "    height=700,\n",
    "    text_auto=False,\n",
    "    aspect=\"auto\",\n",
    "    color_continuous_scale=[[0, \"blue\"], [0.5, \"white\"], [1, \"red\"]],\n",
    "    zmin=-1,\n",
    "    zmax=1,\n",
    "    x=viewer.hall_of_fame.columns[:-1],\n",
    "    y=viewer.hall_of_fame.columns[:-1],\n",
    ")\n",
    "# enlève le fond et la grille\n",
    "fig.update_xaxes(showgrid=False, showline=False, zeroline=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w)\n",
    "plt.plot(viewer.hall_of_fame[\"fitness\"].to_numpy())\n",
    "plt.legend([\"poids\", \"fitness\"])\n",
    "plt.xlabel(\"Individu\")\n",
    "plt.ylabel(\"Valeur\")\n",
    "plt.title(\"Poids et fitness des individus : w = -fitness + max(fitness)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(w)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "ax2.plot(viewer.hall_of_fame[\"fitness\"].to_numpy(), color=\"red\")\n",
    "plt.legend([\"poids\", \"fitness\"])\n",
    "plt.xlabel(\"Individu\")\n",
    "ax.set_ylabel(\"Poids\")\n",
    "ax2.set_ylabel(\"Fitness\")\n",
    "ax2.set_yscale(\"log\")\n",
    "plt.title(\"Poids et fitness des individus : w = absolute(1 / fitness)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taylor Diagram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = viewer.taylor_diagram(1, client=client)\n",
    "# dont show legend\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_biomass_pandas = (\n",
    "    viewer.best_simulation.pint.quantify()\n",
    "    .pint.to(\"mg/meter^2\")\n",
    "    .pint.dequantify()\n",
    "    .to_dataframe()\n",
    "    .pivot_table(index=\"time\", columns=\"functional_group\", values=\"biomass\")\n",
    ")\n",
    "original_biomass_pandas = (\n",
    "    viewer.original_simulation.pint.quantify()\n",
    "    .pint.to(\"mg/meter^2\")\n",
    "    .pint.dequantify()\n",
    "    .to_dataframe()\n",
    "    .pivot_table(index=\"time\", columns=\"functional_group\", values=\"biomass\")\n",
    ")\n",
    "observations_day_pandas = (\n",
    "    observations_selected_without_init.pint.quantify()\n",
    "    .pint.to(\"mg/meter^2\")\n",
    "    .pint.dequantify()\n",
    "    .day.dropna(\"time\")\n",
    "    .to_dataframe()\n",
    "    .reset_index()\n",
    "    .set_index(\"time\")[\"day\"]\n",
    ")\n",
    "observations_night_pandas = (\n",
    "    observations_selected_without_init.pint.quantify()\n",
    "    .pint.to(\"mg/meter^2\")\n",
    "    .pint.dequantify()\n",
    "    .night.dropna(\"time\")\n",
    "    .to_dataframe()\n",
    "    .reset_index()\n",
    "    .set_index(\"time\")[\"night\"]\n",
    ")\n",
    "layer_pandas = epi_layer_depth.pint.dequantify().to_dataframe().reset_index().set_index(\"time\")[\"pelagic_layer_depth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then resample to month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_obs_day = observations_day_pandas.resample(\"ME\").mean()[TIME_START:TIME_END].dropna()\n",
    "monthly_obs_day.index = monthly_obs_day.index.to_period(\"M\").to_timestamp()\n",
    "\n",
    "monthly_obs_night = observations_night_pandas.resample(\"ME\").mean()[TIME_START:TIME_END].dropna()\n",
    "monthly_obs_night.index = monthly_obs_night.index.to_period(\"M\").to_timestamp()\n",
    "\n",
    "monthly_pred_d1n1 = optimized_biomass_pandas.iloc[:, 0].resample(\"ME\").mean()[TIME_START:TIME_END].dropna()\n",
    "monthly_pred_d1n1.index = monthly_pred_d1n1.index.to_period(\"M\").to_timestamp()\n",
    "\n",
    "monthly_pred_d2n1 = optimized_biomass_pandas.iloc[:, 1].resample(\"ME\").mean()[TIME_START:TIME_END].dropna()\n",
    "monthly_pred_d2n1.index = monthly_pred_d2n1.index.to_period(\"M\").to_timestamp()\n",
    "\n",
    "monthly_pred_orignal = original_biomass_pandas.iloc[:, 0].resample(\"ME\").mean()[TIME_START:TIME_END].dropna()\n",
    "monthly_pred_orignal.index = monthly_pred_orignal.index.to_period(\"M\").to_timestamp()\n",
    "\n",
    "monthly_layer = layer_pandas.resample(\"ME\").mean()[TIME_START:TIME_END].dropna()\n",
    "monthly_layer.index = monthly_layer.index.to_period(\"M\").to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram = ModTaylorDiagram()\n",
    "\n",
    "all_model = [monthly_pred_d1n1, monthly_pred_d1n1 + monthly_pred_d2n1, monthly_pred_orignal, monthly_pred_orignal]\n",
    "all_obs = [monthly_obs_day, monthly_obs_night, monthly_obs_day, monthly_obs_night]\n",
    "\n",
    "all_names = [\"HOT Day\", \"HOT Night\", \"Original Day\", \"Original Night\"]\n",
    "\n",
    "for model, obs, name in zip(all_model, all_obs, all_names):\n",
    "    diagram = generate_mod_taylor_diagram(diagram, obs=obs, model=model[obs.index], name=name)\n",
    "diagram.plot()\n",
    "plt.title(\n",
    "    \"Taylor Diagram for Seapodym model during day at HOT station with CAFE NPP : all parameters optimization and 2 groups\"\n",
    ")\n",
    "\n",
    "# export the figure\n",
    "if SAVE:\n",
    "    plt.savefig(f\"Taylor_{export_file_name}.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    diagram.get_stats().to_csv(f\"Stats_{export_file_name}.csv\", index=False)\n",
    "diagram.get_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
