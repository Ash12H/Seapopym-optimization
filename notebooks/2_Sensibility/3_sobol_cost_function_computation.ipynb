{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from dask.distributed import Client\n",
    "from seapopym.configuration.no_transport.parameter import ForcingParameters, ForcingUnit, KernelParameters\n",
    "\n",
    "from seapopym_optimization import wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User parameters\n",
    "\n",
    "A batch of 1000 samples takes about 48 seconds to run on my machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples_by_batch = 1000\n",
    "\n",
    "quantity_of_interest = [\"mean\", \"variance\", \"argmax\"]\n",
    "\n",
    "time_start = \"2005-01-01\"\n",
    "time_start_analysis = \"2006-01-01\"\n",
    "time_end = \"2007-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_locations = pd.read_json(\"../1_data_processing/1_3_Sensibility/stations_locations.json\")\n",
    "stations_locations = stations_locations.set_index(\"name\")\n",
    "stations_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_index_columns = pd.MultiIndex.from_product(\n",
    "    [stations_locations.index, quantity_of_interest], names=[\"station\", \"quantity_of_interest\"]\n",
    ")\n",
    "column_index_flatten = pd.Index(\n",
    "    [f\"{station}_{quantity_of_interest}\" for station, quantity_of_interest in multi_index_columns], name=\"station\"\n",
    ")\n",
    "multi_index_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples (sobol sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_parameters = pd.read_parquet(\"./input_samples.parquet\")\n",
    "input_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the output file. This file will be filled batch after batch with QoI values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sobol_index_filepath = Path(\"./output_sobol_index.parquet\")\n",
    "if output_sobol_index_filepath.exists():\n",
    "    output_sobol_index = pd.read_parquet(output_sobol_index_filepath)\n",
    "else:\n",
    "    output_sobol_index = pd.DataFrame(columns=multi_index_columns)\n",
    "    output_sobol_index.to_parquet(output_sobol_index_filepath)\n",
    "output_sobol_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Cost function definition\n",
    "\n",
    "Prepare forcing and parameters definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_forcing = xr.open_dataset(\"../1_data_processing/1_3_Sensibility/all_stations.zarr\", engine=\"zarr\")\n",
    "input_forcing = input_forcing.sel(time=slice(time_start, time_end))\n",
    "input_forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCING_PARAMETERS = ForcingParameters(\n",
    "    temperature=ForcingUnit.from_dataset(forcing=input_forcing, name=\"T\", resolution=0.08333, timestep=1),\n",
    "    primary_production=ForcingUnit.from_dataset(input_forcing, name=\"npp\", resolution=0.08333, timestep=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_model_generator_no_transport(fg_parameters):\n",
    "    fg_parameters = wrapper.FunctionalGroupGeneratorNoTransport(np.array([fg_parameters]))\n",
    "    return wrapper.model_generator_no_transport(\n",
    "        fg_parameters=fg_parameters,\n",
    "        forcing_parameters=FORCING_PARAMETERS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Official scoring function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quantity_of_interest(biomass_forcing_station, station):\n",
    "    return (\n",
    "        float(biomass_forcing_station.mean().data),\n",
    "        float(biomass_forcing_station.var().data),\n",
    "        int(biomass_forcing_station.argmax(\"time\").data),  # TODO: Compute the DayOfYear of the argmax\n",
    "    )\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def cost_function(x: np.ndarray):\n",
    "    energy_transfert, tr_0, gamma_tr, inv_lambda_0, gamma_inv_lambda = x.T\n",
    "    fg_parameters = [0, 0, energy_transfert, tr_0, gamma_tr, inv_lambda_0, gamma_inv_lambda]\n",
    "\n",
    "    model = wrapper_model_generator_no_transport(fg_parameters)\n",
    "\n",
    "    model.run()\n",
    "    biomass_forcing = model.export_biomass().sel(time=slice(time_start_analysis, time_end))\n",
    "\n",
    "    results = []\n",
    "    for station in stations_locations.index:\n",
    "        biomass_forcing_station = biomass_forcing.sel(\n",
    "            latitude=stations_locations.loc[station, \"latitude\"],\n",
    "            longitude=stations_locations.loc[station, \"longitude\"],\n",
    "            functional_group=0,\n",
    "        )\n",
    "        results += compute_quantity_of_interest(biomass_forcing_station, station)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_cost_function_execution(input_parameters: pd.DataFrame) -> np.ndarray:\n",
    "    resultats = [cost_function(param) for param in input_parameters.to_numpy()]\n",
    "    return np.array(dask.compute(*resultats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST FUNCTION\n",
    "# def batch_cost_function_execution(input_parameters: pd.DataFrame) -> np.ndarray:\n",
    "#     return np.full((input_parameters.shape[0], len(quantity_of_interest)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run as much batch you can\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_number in range(0, (len(input_parameters) // nb_samples_by_batch) + 1):\n",
    "    min_batch = batch_number * nb_samples_by_batch\n",
    "    max_batch = min(batch_number * nb_samples_by_batch + nb_samples_by_batch, len(input_parameters))\n",
    "    print(f\"Batch {batch_number} = {min_batch} : {max_batch}\")\n",
    "\n",
    "    if not (max_batch) in output_sobol_index.index:\n",
    "        batch_samples = input_parameters.iloc[\n",
    "            batch_number * nb_samples_by_batch : batch_number * nb_samples_by_batch + nb_samples_by_batch\n",
    "        ]\n",
    "\n",
    "        results = batch_cost_function_execution(batch_samples)\n",
    "        results = pd.DataFrame(data=results, columns=multi_index_columns, index=batch_samples.index)\n",
    "\n",
    "        output_sobol_index = pd.concat([output_sobol_index, results])\n",
    "        output_sobol_index.to_parquet(output_sobol_index_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sobol_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
