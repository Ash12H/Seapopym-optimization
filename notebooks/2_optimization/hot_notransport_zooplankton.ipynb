{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import dask\n",
    "import dask.distributed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import xarray as xr\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from deap import algorithms, base, creator, tools\n",
    "from plotly import graph_objects as go\n",
    "from seapopym.configuration.no_transport.configuration import NoTransportConfiguration\n",
    "from seapopym.configuration.no_transport.parameter import (\n",
    "    EnvironmentParameter,\n",
    "    ForcingParameters,\n",
    "    FunctionalGroups,\n",
    "    KernelParameters,\n",
    "    NoTransportParameters,\n",
    ")\n",
    "from seapopym.configuration.parameters.parameter_environment import ClientParameter\n",
    "from seapopym.configuration.parameters.parameter_forcing import ForcingUnit\n",
    "from seapopym.configuration.parameters.parameter_functional_group import (\n",
    "    FunctionalGroupUnit,\n",
    "    FunctionalGroupUnitMigratoryParameters,\n",
    "    FunctionalGroupUnitRelationParameters,\n",
    ")\n",
    "from seapopym.logging.custom_logger import logger, set_debug, set_error\n",
    "from seapopym.model.no_transport_model import NoTransportModel\n",
    "from seapopym.standard.units import StandardUnitsLabels\n",
    "\n",
    "random.seed(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.set_options(\n",
    "    keep_attrs=True,\n",
    "    display_expand_attrs=False,\n",
    "    display_expand_data=False,\n",
    "    display_expand_coords=False,\n",
    "    display_expand_data_vars=False,\n",
    ")\n",
    "\n",
    "WET_TO_CARBON = 1 / 11.9\n",
    "\n",
    "logger.setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=4, threads_per_worker=2)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forcing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forcing data from seapodym model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_data = xr.open_dataset(\"../1_data_processing/1_1_Forcing/hot_cmems.zarr\", engine=\"zarr\")\n",
    "hot_data[\"T\"].attrs[\"units\"] = StandardUnitsLabels.temperature.units\n",
    "hot_data.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation data from Hot station\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_obs = xr.open_dataset(\"../1_data_processing/1_1_Forcing/hot_obs.zarr\", engine=\"zarr\")\n",
    "hot_obs.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the observed zooplankton data to be used further in the cost function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo_obs = (\n",
    "    (hot_obs[\"dwt_migrant\"] + hot_obs[\"dwt_resident\"])\n",
    "    .sum(\"frac\")\n",
    "    .sum(\"depth\")\n",
    "    .cf.isel(Y=0, X=0)\n",
    "    .pint.quantify()\n",
    "    .pint.to(\"kg/m^2\")\n",
    ")\n",
    "zoo_obs = zoo_obs.where(zoo_obs > 0, drop=True) * WET_TO_CARBON\n",
    "zoo_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to automatically generate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fgroup(\n",
    "    tr_max: float = 10.38,\n",
    "    tr_rate: float = -0.11,\n",
    "    inv_lambda_max: float = 150,\n",
    "    inv_lambda_rate: float = 0.15,\n",
    "    day_layer: float = 1,\n",
    "    night_layer: float = 1,\n",
    "    energy_transfert: float = 0.1668,\n",
    ") -> FunctionalGroups:\n",
    "    \"\"\"Generate a FunctionalGroups object with the given parameters.\"\"\"\n",
    "    return FunctionalGroups(\n",
    "        functional_groups=[\n",
    "            FunctionalGroupUnit(\n",
    "                name=f\"D{day_layer}N{night_layer}\",\n",
    "                migratory_type=FunctionalGroupUnitMigratoryParameters(day_layer=day_layer, night_layer=night_layer),\n",
    "                functional_type=FunctionalGroupUnitRelationParameters(\n",
    "                    inv_lambda_max=inv_lambda_max,\n",
    "                    inv_lambda_rate=inv_lambda_rate,\n",
    "                    temperature_recruitment_rate=tr_rate,\n",
    "                    cohorts_timesteps=[1] * np.ceil(tr_max).astype(int),\n",
    "                    temperature_recruitment_max=tr_max,\n",
    "                ),\n",
    "                energy_transfert=energy_transfert,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def gen_model(forcing_parameters, functional_groups_parameters, **kwargs) -> NoTransportModel:\n",
    "    \"\"\"\n",
    "    Generate a NoTransportModel with the given parameters.\n",
    "\n",
    "    kwargs:\n",
    "        - environment_parameters: EnvironmentParameter = EnvironmentParameter,\n",
    "        - kernel_parameters: KernelParameters = KernelParameters\n",
    "    \"\"\"\n",
    "    return NoTransportModel(\n",
    "        configuration=NoTransportConfiguration(\n",
    "            parameters=NoTransportParameters(\n",
    "                forcing_parameters=forcing_parameters,\n",
    "                functional_groups_parameters=functional_groups_parameters,\n",
    "                **kwargs,\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forcing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_data_parameter = ForcingParameters(\n",
    "    temperature=ForcingUnit(forcing=hot_data[\"T\"], resolution=0.08333),\n",
    "    primary_production=ForcingUnit(forcing=hot_data[\"npp\"], resolution=0.08333),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial conditions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgroups = gen_fgroup()\n",
    "setup_model = gen_model(\n",
    "    hot_data_parameter,\n",
    "    fgroups,\n",
    "    kernel_parameters=KernelParameters(compute_initial_conditions=True, compute_preproduction=True),\n",
    ")\n",
    "setup_model.run()\n",
    "initial_conditions = setup_model.export_initial_conditions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the forcing data with initial conditions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_data_parameter = ForcingParameters(\n",
    "    temperature=ForcingUnit(forcing=hot_data[\"T\"], resolution=0.08333),\n",
    "    primary_production=ForcingUnit(forcing=hot_data[\"npp\"], resolution=0.08333),\n",
    "    initial_condition_biomass=ForcingUnit(forcing=initial_conditions[\"initial_condition_biomass\"], resolution=0.08333),\n",
    "    initial_condition_production=ForcingUnit(\n",
    "        forcing=initial_conditions[\"initial_condition_production\"], resolution=0.08333\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(args: tuple[float, float, float, float, float]):\n",
    "    \"\"\"Use the Mean Absolute Error (MAE) method.\"\"\"\n",
    "    (\n",
    "        energy_transfert,\n",
    "        tr_max,\n",
    "        tr_rate,\n",
    "        inv_lambda_max,\n",
    "        inv_lambda_rate,\n",
    "    ) = args\n",
    "    if tr_rate > 0:\n",
    "        tr_rate = -tr_rate\n",
    "    fgroups = gen_fgroup(\n",
    "        energy_transfert=energy_transfert,\n",
    "        tr_max=tr_max,\n",
    "        tr_rate=tr_rate,\n",
    "        inv_lambda_max=inv_lambda_max,\n",
    "        inv_lambda_rate=inv_lambda_rate,\n",
    "    )\n",
    "\n",
    "    setup_model = gen_model(hot_data_parameter, fgroups)\n",
    "    setup_model.run()\n",
    "\n",
    "    biomass_pred = setup_model.export_biomass().cf.isel(functional_group=0, X=0, Y=0).pint.quantify()\n",
    "    cost = float(np.abs((zoo_obs - biomass_pred).pint.dequantify()).mean())\n",
    "    return (cost,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEAP - Genetic algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the population of the genetic algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_exclusive(a, b):\n",
    "    if a >= b:\n",
    "        raise ValueError(\"La borne inférieure doit être inférieure à la borne supérieure.\")\n",
    "\n",
    "    while True:\n",
    "        value = random.uniform(a, b)\n",
    "        if value != a and value != b:\n",
    "            return value\n",
    "\n",
    "\n",
    "parameters_boundaries = {\n",
    "    \"energy_transfert\": (0, 0.5),\n",
    "    \"tr_max\": (0, 50),\n",
    "    \"tr_rate\": (0, 1),\n",
    "    \"inv_lambda_max\": (1, 1000),\n",
    "    \"inv_lambda_rate\": (0, 1),\n",
    "}\n",
    "lower_boundary = [values[0] for values in parameters_boundaries.values()]\n",
    "upper_boundary = [values[1] for values in parameters_boundaries.values()]\n",
    "\n",
    "ETA = 0.1\n",
    "INDPB = 0.05\n",
    "CXPB = 0.5\n",
    "MUTPB = 0.1\n",
    "NGEN = 15\n",
    "number_of_individuals = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "\n",
    "\n",
    "creator.create(\"Fitness\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.Fitness)\n",
    "for parameter, boundaries in parameters_boundaries.items():\n",
    "    lb, ub = boundaries\n",
    "    toolbox.register(parameter, random_exclusive, lb, ub)\n",
    "toolbox.register(\n",
    "    \"individual\",\n",
    "    tools.initCycle,\n",
    "    creator.Individual,\n",
    "    (toolbox.energy_transfert, toolbox.tr_max, toolbox.tr_rate, toolbox.inv_lambda_max, toolbox.inv_lambda_rate),\n",
    "    n=1,\n",
    ")\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", cost_function)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutPolynomialBounded, eta=ETA, indpb=INDPB, low=lower_boundary, up=upper_boundary)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function to run the genetic algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_manual(population, toolbox, cxpb, mutpb, ngen, verbose=__debug__):\n",
    "    halloffame = tools.HallOfFame(100)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = [\"gen\", \"nevals\"] + (stats.fields if stats else [])\n",
    "\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    invalid_ind_as_list = [list(ind) for ind in invalid_ind]  # For compatibility with DASK\n",
    "    futures_results = client.map(toolbox.evaluate, invalid_ind_as_list)\n",
    "    fitnesses = client.gather(futures_results)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is not None:\n",
    "        halloffame.update(population)\n",
    "\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "        # Select the next generation individuals\n",
    "        offspring = toolbox.select(population, len(population))\n",
    "\n",
    "        # Vary the pool of individuals\n",
    "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        invalid_ind_as_list = [list(ind) for ind in invalid_ind]  # For compatibility with DASK\n",
    "        futures_results = client.map(toolbox.evaluate, invalid_ind_as_list)\n",
    "        fitnesses = client.gather(futures_results)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        if halloffame is not None:\n",
    "            halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook, halloffame\n",
    "\n",
    "\n",
    "pop, logbook, hof = main_manual(\n",
    "    population=toolbox.population(n=number_of_individuals),\n",
    "    toolbox=toolbox,\n",
    "    cxpb=CXPB,\n",
    "    mutpb=MUTPB,\n",
    "    ngen=NGEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(nrows=1, ncols=5, figsize=(10, 5))\n",
    "for idx, ax, name in zip(range(5), [ax1, ax2, ax3, ax4, ax5], parameters_boundaries.keys()):\n",
    "    ax.set_title(name)\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    ax.set_xlabel(\"Parameter\")\n",
    "    ax.violinplot(np.asarray(hof.items)[:, idx])\n",
    "\n",
    "# print the main title\n",
    "plt.suptitle(f\"Violin plot of the parameters for the {len(hof.items)} best individuals\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters initial values:\n",
    "\n",
    "-   energy_transfert: float = 0.1668\n",
    "-   tr_max: float = 10.38\n",
    "-   tr_rate: float = -0.11\n",
    "-   inv_lambda_max: float = 150\n",
    "-   inv_lambda_rate: float = 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best individual is: \")\n",
    "for name, value in zip(parameters_boundaries.keys(), hof[0]):\n",
    "    print(f\"{name} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model for this parameters\n",
    "best_run = gen_model(\n",
    "    hot_data_parameter,\n",
    "    gen_fgroup(\n",
    "        energy_transfert=hof[0][0],\n",
    "        tr_max=hof[0][1],\n",
    "        tr_rate=hof[0][2],\n",
    "        inv_lambda_max=hof[0][3],\n",
    "        inv_lambda_rate=hof[0][4],\n",
    "    ),\n",
    ")\n",
    "best_run.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_run.export_biomass()[0, :, 0, 0].to_dataframe()[\"biomass\"]\n",
    "obs = zoo_obs.rename(\"biomass_obs\").to_dataframe()[\"biomass_obs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go.Figure(\n",
    "    [\n",
    "        go.Scatter(x=pred.index, y=pred, name=\"Prediction\"),\n",
    "        go.Scatter(x=obs.index, y=obs, name=\"Observations\"),\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
